# -*- coding: utf-8 -*-
"""SystemRecomendation_AnimeRecomendation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gPaQyWwvb9twoWIgFxRRhgr_6S3shIFr

# Laporan Project Machine learning - Candra Burhanudin
# Dataset : [Anime Recommendations Database](https://www.kaggle.com/datasets/CooperUnion/anime-recommendations-database?select=rating.csv)

## Data Understanding

> install paket kaggle (dataset berasal dari platform KAGGLE) & Import Library yang dibutuhkan
"""

!pip install kaggle

"""> membuat direktori .kaggle di dalam direktori beranda user /root/.kaggle lalu menyalin file kaggle.json ke direktori .kaggle"""

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/

"""> atur izin akses file kaggle.json menjadi 600 (hanya pemilik file yg memiliki izin read & write. pengguna lain tidak diizinkan) dan mulai proses unduh dataset menggunakan kaggle datasets download"""

! chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d CooperUnion/anime-recommendations-database

import pandas as pd
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from zipfile import ZipFile
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

"""> ekstrak dataset menggunakan libbrary zipfile di direktori /content/ / lalu untuk membaca dataset format csv dilakukan dengan library pandas pd.read_csv(alamat file)"""

zip_file_path = '/content/anime-recommendations-database.zip'
with ZipFile(zip_file_path, 'r') as zip_ref :
  zip_ref.extractall('/content/')

df_anime = pd.read_csv('/content/anime.csv')
df_rating = pd.read_csv('/content/rating.csv')
print('jumlah data anime : ', len(df_anime.anime_id.unique()))
print('jumlah data penilaian yang diberikan pengguna : ',len(df_rating.rating))
print('jumlah user yang memberikan rating : ',len(df_rating.user_id.unique()))

"""## Univariate Exploratory Data Analysis
Anime.csv
* anime_id - myanimelist.net's unique id identifying an anime.
name - full name of anime.
* genre - comma separated list of genres for this anime.
* type - movie, TV, OVA, etc.
episodes - how many episodes in this show. (1 if movie).
* rating - average rating out of 10 for this anime.
* members - number of community members that are in this anime's
"group".

Rating.csv

* user_id - non identifiable randomly generated user id.
* anime_id - the anime that this user has rated.
* rating - rating out of 10 this user has assigned (-1 if the user watched it but didn't assign a rating).
> pada proyek ini, kita akan mengeksplorasi beberapa variabel saja, antara lain: df_anime, df_rating.

### Data Anime

> memotong data hingga 10000 record
"""

df_anime = df_anime[:10000]

df_anime.info()

print('banyak data Anime : ',len(df_anime.anime_id.unique()))
print('jumlah genre Anime : ',len(df_anime.genre.unique()))

"""> Filter Data dengan membuang data yang tidak pantas digunakan"""

df_anime_filtered = df_anime[~df_anime['genre'].apply(lambda x: isinstance(x, float) or 'Hentai' in x)]

print('banyak data Anime setelah filtrasi : ',len(df_anime_filtered.anime_id.unique()))
print('jumlah genre Anime setelah filtrasi: ',len(df_anime_filtered.genre.unique()))
print('genre Anime setelah filtrasi: ',df_anime_filtered.genre.unique())

df_anime_filtered

"""### Data Anime User Rating

memotong data hingga 10000 record
"""

df_rating = df_rating[:10000]

df_rating.info()

df_rating.sample(5)

print('banyak data User : ',len(df_rating.user_id.unique()))
print('banyak data Anime : ',len(df_rating.anime_id.unique()))

# Salin slice DataFrame ke DataFrame baru
df_rating_copy = df_rating.copy()

"""> menambahkan huruf pada `user_id` agar id lebih bersifat unik"""

df_rating_copy.loc[:,'user_id'] = 'U' + df_rating_copy['user_id'].astype(str)

"""> karena jumlah banyak anime pada `df_rating` dan `df_anime_filtered` berbeda karena sudah melalui tahap filtered maka pada `df_rating` dilakukan penyesuaian agar jumlah anime sama sesuai dengan anime_id pada `df_anime_filtered`

> mengganti nilai rating yang invalid (nilai -1 diganti menjadi 0)
"""

df_rating_copy['rating'] = df_rating_copy['rating'].replace(-1, 0)

df_rating_filtered = df_rating_copy[df_rating_copy['anime_id'].isin(df_anime_filtered['anime_id'])]
df_rating_filtered.sample(5)

"""> Menselaraskan  anime_id pada `df_anime_filtered` dengan `df_rating_filtered` agar jumlahnya sama"""

df_anime_filtered = df_anime_filtered[df_anime_filtered['anime_id'].isin(df_rating_filtered['anime_id'])]

df_anime_filtered

print('banyak data Anime setelah filtrasi di dataframe df_anime_filtered: ',len(df_anime_filtered.anime_id.unique()))

print('banyak data pengguna setelah filtrasi : ',len(df_rating_filtered.user_id.unique()))
print('banyak data Anime setelah filtrasi di dataframe df_rating_filtered : ',len(df_rating_filtered.anime_id.unique()))
print('rating yang diberikan oleh pengguna :' ,(df_rating_filtered.rating.unique()))

df_rating_filtered.sample(5)

"""### Distribusi Data Anime Dan Data Rating User"""

df_anime_filtered.describe()

df_rating_filtered.describe()

"""## Data Preparation

> Cek Missing Value
"""

df_anime_filtered.isnull().sum()

df_rating_filtered.isnull().sum()

"""> Menggabungkan data anime"""

anime_all = np.concatenate((
    df_anime_filtered.anime_id.unique(),
    df_rating_filtered.anime_id.unique()
))

anime_all = np.sort(np.unique(anime_all))
print('jumlah seluruh data anime berdasarkan anime_id: ', len(anime_all))

all_anime = pd.merge( df_rating_filtered, df_anime_filtered , on='anime_id')
all_anime.sample(10)

"""> Mengurutkan data secara ascending menurut fitur anime_id"""

preparation = all_anime
preparation.sort_values('anime_id')

"""> data yang digunakan hanya menggunakan data unik untuk dimasukkan ke dalam proses pemodelan, oleh karena itu perlu menghapus data yang duplikat"""

preparation = preparation.drop_duplicates('anime_id')
preparation.sort_values('anime_id')

"""> Konversi Data series menjadi list"""

anime_id = preparation['anime_id'].tolist()
anime_name = preparation['name'].tolist()
anime_genre = preparation['genre'].tolist()
print(len(anime_id))
print(len(anime_name))
print(len(anime_genre))

"""> membuat dictionary untuk menentukan pasangan key-value pada data anime_id, anime_name, anime_genre"""

anime_new = pd.DataFrame({
    'id': anime_id,
    'anime_name': anime_name,
    'anime_genre': anime_genre
})
anime_new

"""### Encoding Fitur User_id

> mengubah user_id menjadi list tanpa nilai yang sama
"""

user_ids = df_rating_filtered['user_id'].unique().tolist()
print('list user_id ', user_ids)

""" > melakukan encoding user_id & encoding angka ke user_id"""

user_to_user_encoded = {x : i for i,x in enumerate(user_ids)}
print('encode user_id : ',user_to_user_encoded)

user_encoded_to_user = {i : x for i,x in enumerate(user_ids)}
print('encoded angka ke user_id',user_encoded_to_user)

"""### Encoding Fitur anime_id

> petakan user_id dan dan anime_id ke dataframe yang berkaitan
"""

anime_ids = df_rating_filtered['anime_id'].unique().tolist()
print(anime_ids)

"""> melakukan proses encoding anime_id dan proses encoding angka ke anime_id"""

anime_to_anime_encoded = {x: i for i, x in enumerate(anime_ids)}
print('encode anime_id : ',anime_to_anime_encoded)
anime_encoded_to_anime = {i: x for i, x in enumerate(anime_ids)}
print('encode angka ke anime_id : ',anime_encoded_to_anime)

"""### Membuat fitur user & anime

> petakan user_id dan anime_id ke dataframe
"""

df_rating_filtered_copy = df_rating_filtered.copy()

df_rating_filtered_copy['user']= df_rating_filtered_copy['user_id'].map(user_to_user_encoded)
df_rating_filtered_copy['anime']= df_rating_filtered_copy['anime_id'].map(anime_to_anime_encoded)

df_rating_filtered_copy['user']

df_rating_filtered_copy.sample(5)

"""> cek missing value pada dataframe rating"""

df_rating_filtered_copy.isnull().sum()

df_rating_filtered_copy.sample(10)

"""### Standarisasi Data

> cek beberapa hal dalam data seperti jumlah user, jumlah anime, kemudian mengubah nilai rating menjadi float
"""

num_users = len(user_to_user_encoded)
num_anime = len(anime_encoded_to_anime)
df_rating_filtered_copy['rating'] = df_rating_filtered_copy['rating'].values.astype(np.float32)
min_rating = min(df_rating_filtered['rating'])
max_rating = max(df_rating_filtered['rating'])
print('Number of User: {}, Number of Anime: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_anime, min_rating, max_rating
))

"""## Sistem Rekomendasi Dengan Teknik Content-Based

### TF-IDF Vectorizer
"""

data = anime_new
data.sample(5)

"""> pada tahap ini akan membangun sistem rekomendasi dengan teknik content-based berdasarkan genre anime yang tersedia pada dataset"""

tf = TfidfVectorizer()
tf.fit(data['anime_genre'])
tf.get_feature_names_out()

tfidf_matrix = tf.fit_transform(data['anime_genre'])
tfidf_matrix.shape

"""> mproses menghasilkan vektor tf-idf dalam bentuk matriks"""

tfidf_matrix.todense()

pd.DataFrame(
    tfidf_matrix.todense(),
    columns = tf.get_feature_names_out() ,
    index = data.anime_name
).sample(44,axis=1).sample(10, axis=0)

"""### Cosine *Similarity*"""

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""> menghitung cosine similarity dataframe tfidf_matrix dengan satu barus"""

cosine_sim_df = pd.DataFrame(cosine_sim, index=data['anime_name'], columns=data['anime_name'])
print('shape', cosine_sim_df.shape)

cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""### Mendapatkan Rekomendasi
Cara Kerja Contohnya Pengguna X pernah menonton Anime Naruto dengan Genre Action, Comedy, Martial Arts, Shounen. Kemudian, saat pengguna tersebut berencana untuk menonton dari anime lain, sistem akan merekomendasikan anime yang relevan berdasarkan kesamaan yang dihitung dengan cosine_similarity

"""

def  animes_recommendations(nama_anime, similarity_data=cosine_sim_df, items=data[['anime_name', 'anime_genre']], k=5):
  index = similarity_data.loc[:,nama_anime].to_numpy().argpartition(
      range(-1, -k, -1))

  closest = similarity_data.columns[index[-1:-(k+2):-1]]
  closest = closest.drop(nama_anime, errors='ignore')
  return pd.DataFrame(closest).merge(items).head(k)

data[data.anime_name.eq('Naruto')]

"""> Mendapatkan rekomendasi anime"""

animes_recommendations('Naruto')

"""## Sistem Rekomendasi Dengan Collaborative Filtering

### Split Data Train Val

> cek kembali dataset
"""

df_rating_filtered_copy.sample(frac=1, random_state=42)

"""> membuat variabel x untuk mencocokan data user dan anime menjadi satu value

"""

x = df_rating_filtered_copy[['user','anime']].values
x

"""> membuat variabel y untuk membuat rating dari hasil

"""

y =df_rating_filtered_copy['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

y

"""> membagi data menjadi 80% data training dan 20% data validasi

"""

train_indices = int(0.8 * df_rating_filtered_copy.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x,y)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
label= ['Training','validation']
colors=['tab:blue', 'tab:green']
myexplode = [0.1, 0]
fig1, ax1 = plt.subplots(figsize=(3, 3))
data= [int(len(x_train)),int(len(x_val))]
plt.pie(data, labels=label, autopct='%1.1f%%', startangle=90, colors=colors,explode = myexplode)
plt.title('Dataset Split')
ax1.axis('equal')
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
fig2,ax2 = plt.subplots(figsize=(5, 3))

datasplit = ['training', 'validation']
counts_dataset =  [len(x_train),len(x_val)]
bar_labels = [len(x_train),len(x_val)]
bar_colors = ['tab:blue','tab:green']

ax2.bar(datasplit, counts_dataset,label=bar_labels, color=bar_colors)
ax2.set_ylabel('jumlah dataset')
ax2.set_title('perbandingan jumlah data')
ax2.legend(title='jumlah data')
plt.show()

df_rating_filtered_copy['rating'].value_counts().sort_index()

df_rating_filtered_copy.groupby('rating').size().plot(kind='bar')

"""### Proses Training

model menghitung skor kecocokan antara pengguna dan data anime dengan teknik embedding
* Pertama, kita melakukan proses embedding terhadap data user dan data anime.
* Selanjutnya, lakukan operasi perkalian dot product antara embedding user dan data anime.
* kita juga dapat menambahkan bias untuk setiap user dan data anime.
* Skor kecocokan ditetapkan dalam skala [0,1] dengan fungsi aktivasi sigmoid.
"""

class RecommenderNet(tf.keras.Model):
  def __init__(self, num_users, num_anime, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_anime = num_anime
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding(
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1)
    self.anime_embedding = layers.Embedding(
        num_anime,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.anime_bias = layers.Embedding(num_anime, 1)

  def call(self,inputs):
    user_vector = self.user_embedding(inputs[:,0])
    user_bias = self.user_bias(inputs[:, 0])
    anime_vector = self.anime_embedding(inputs[:, 1])
    anime_bias = self.anime_bias(inputs[:, 1])

    dot_user_anime = tf.tensordot(user_vector, anime_vector, 2)
    x = dot_user_anime + user_bias + anime_bias

    return tf.nn.sigmoid(x)

"""> selanjutnya proses compile moded"""

model = RecommenderNet(num_users, num_anime, 50)
model.compile(
  loss = tf.keras.losses.BinaryCrossentropy(),
  optimizer = keras.optimizers.Adam(learning_rate=0.002),
  metrics=[tf.keras.metrics.RootMeanSquaredError()],
)

"""> Mulai Proses Training"""

history = model.fit(
    x = x_train,
    y = y_train,
    epochs = 100,
    validation_data = (x_val, y_val)
)

evaluation = model.evaluate(x_val, y_val)

print("val_Loss :", evaluation[0])
print("Root Mean Squared Error :", evaluation[1])

"""### Visualisasi Metrik"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc= 'upper left')
plt.show()

"""> mengambil sample user"""

anime_df = anime_new
df = df_rating_filtered
user_id = df.user_id.sample(1).iloc[0]
anime_visited_by_user = df[df.user_id == user_id]

anime_not_visited = anime_df[~anime_df['id'].isin(anime_visited_by_user.user_id.values)]['id']
anime_not_visited = list(
    set(anime_not_visited)
    .intersection(set(anime_to_anime_encoded.keys()))
)

anime_not_visited = [[anime_to_anime_encoded.get(x)] for x in anime_not_visited]
user_encoder = user_to_user_encoded.get(user_id)
user_anime_array = np.hstack(
    ([[user_encoder]] * len(anime_not_visited), anime_not_visited)
)

"""> Percobaan Model Prediksi"""

ratings = model.predict(user_anime_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_anime_ids = [
    anime_encoded_to_anime.get(anime_not_visited[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('Anime with high ratings from user')
print('----' * 8)

top_anime_user = (
    anime_visited_by_user.sort_values(
        by = 'rating',
        ascending = False
    )
    .head(5)
    .anime_id.values
)

anime_df_rows = anime_df[anime_df['id'].isin(top_anime_user)]
for row in anime_df_rows.itertuples():
    print(row.anime_name, ':', row.anime_genre)

print('----' * 8)
print('Top 10 Anime recommendation')
print('----' * 8)

recommended_anime = anime_df[anime_df['id'].isin(recommended_anime_ids)]
for row in recommended_anime.itertuples():
    print(row.anime_name, ':', row.anime_genre)